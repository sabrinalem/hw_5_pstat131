---
title: "hw_5"
author: "Sabrina Lem"
date: "5/13/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidymodels)
library(tidyverse)
library(glmnet)
library(ggplot2)
tidymodels_prefer()
data <-read_csv('Pokemon.csv')
```
Exercise 1:
```{r}
pokemon_clean <- janitor::clean_names(data)
```
clean names helps us identify variables easier in R. Before clean names some of the variables were labeled with two words. Clean names connects these words with underscores, so we are able to call them in the script. 
\
\
Exercise 2: 
```{r}
plot <- ggplot(data=pokemon_clean, aes(x = type_1)) + 
  geom_bar()
plot
pokemon <- pokemon_clean %>% filter(type_1 == "Bug"|type_1 == "Fire"|
                                      type_1 == "Grass"|type_1 == "Normal"|
                                      type_1 == "Water"|type_1 == "Psychic")
pokemon$type_1 = factor(pokemon$type_1)
pokemon$legendary = factor(pokemon$legendary)
```
There are 18 different classes in the type_1 outcome variable. Flying has a lot fewer Pokemon than any of the other types.  
Exercise 3:
```{r}
set.seed(1027)
pokemon_split <- initial_split(pokemon, prop= 0.7, strata = "type_1")

pokemon_train <- training(pokemon_split)
pokemon_test <- testing(pokemon_split)

dim(pokemon_train)[1]/nrow(pokemon)
dim(pokemon_test)[1]/nrow(pokemon)

pokemon_folds <- vfold_cv(pokemon_train, strata = "type_1", v = 5)
```
The primary type variable is not binary. There are 6 possible outcomes for the primary type. Thus there when split in the k-folds, the randomization may not lead to representative subgroups. Stratification helps to ensure that the splits and thus the subgroups will represent the distribution of the different primary types.
\
\ 
Exercise 4:
```{r}
pokemon_recipe <- recipe(type_1 ~ legendary + generation + sp_atk + 
                           attack + speed + defense + 
                           hp + sp_def, pokemon_train) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) 
```
Exercise 5:
```{r}
elas_spec <-multinom_reg(penalty = tune(), mixture = tune() ) %>%
  set_engine("glmnet")
elas_wkfl <- workflow() %>%
  add_recipe(pokemon_recipe) %>%
  add_model(elas_spec)

penalty_grid <- grid_regular(penalty(range = c(-5,5)), mixture(range=c(0,1)), levels = 10)
```
There are 10 levels and five folds. Thus for each training fold, (4 training folds) there will be 10 models. Thus there will be 40 models in total.
\
\
Exercise 6:
```{r}
tune_res <- tune_grid(
  elas_wkfl,
  resamples = pokemon_folds,
  grid = penalty_grid
)
tune_res
autoplot(tune_res)
```
Smaller values of of penalty and mixture have higher and better accuracy and ROC AUC.
\
\
Exercise 7:
```{r}
best_penalty <- select_best(tune_res, metric = "roc_auc")
best_penalty

elas_final <- finalize_workflow(elas_wkfl, best_penalty)

elas_final_fit <- fit(elas_final, data = pokemon_train)

aug <- augment(elas_final_fit, new_data = pokemon_test) 
aug
```
Exercise 8:
```{r}
aug %>% roc_auc(truth = type_1, estimate =c(
  .pred_Bug, .pred_Fire, .pred_Grass, .pred_Normal,
  .pred_Psychic, .pred_Water))

aug %>% roc_curve(truth = type_1, estimate =c(
  .pred_Bug, .pred_Fire, .pred_Grass, .pred_Normal,
  .pred_Psychic, .pred_Water)) %>%
  autoplot()

aug %>% conf_mat(truth = type_1, estimate =.pred_class) %>%
  autoplot(type = "heatmap")
```
Bug, Psychic, and Normal primary types have the best ROC AUC curves. While Fire, Grass, and Water have ROC AUC curves that cover far less area. The model was not extremely accurate. Some variables were predicted better than others. Looking at the diagonals in the confusion matrix, we can see that there are a range of True Positive values. Water and Normal had high true positive counts of 20 and 19, respectively. However, Grass and Fire both had 0 True Positive counts. Psychic and Bug both had a TP count of 4, which is also not great. So overall, the model did not do very well.

